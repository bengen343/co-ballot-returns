{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import datetime\n",
    "import ftplib\n",
    "import glob\n",
    "import operator\n",
    "import os\n",
    "import pytz\n",
    "import zipfile\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.image as figure\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ftplib import FTP\n",
    "from ftplib import FTP_TLS\n",
    "from datetime import timedelta, datetime\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Commencing mail-in return analysis at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "\n",
    "# Ballot return file variables\n",
    "return_zip_file = r'D:\\Users\\bengen343\\Documents\\2020_Jun_Prim_CE-068_Voters_With_Ballots_List_Public.zip'\n",
    "return_txt_file = r'D:\\Users\\bengen343\\Documents\\2020_Jun_Prim_CE-068_Voters_With_Ballots_List_Public.txt'\n",
    "return_local_directory = r'D:\\Users\\bengen343\\Documents'\n",
    "\n",
    "# Targeting variables\n",
    "target_csv_file = r'W:\\My Documents\\2020-co-primary-eis-targets.csv'\n",
    "target_geographies_dict = {'Huerfano':'COUNTY', 'Mesa':'COUNTY', 'Montezuma':'COUNTY', 'State Senate 8':'STATE_SENATE', \n",
    "                           'State House 22':'STATE_HOUSE', 'State House 48':'STATE_HOUSE', 'State House 49':'STATE_HOUSE', \n",
    "                           'State House 63':'STATE_HOUSE'}\n",
    "target_crosstabs_file = r'W:\\My Documents\\TargetsCOPrimaryCrosstabs.xlsx'\n",
    "\n",
    "# Result file variables\n",
    "result_zip_file = r'W:\\My Documents\\detailxls.zip'\n",
    "result_xls_file = r'W:\\My Documents\\detail.xls'\n",
    "result_local_directory = r'W:\\My Documents'\n",
    "\n",
    "# Voter file variables\n",
    "voter_file_directory = r'W:\\My Documents\\Registration'\n",
    "voter_history_directory = r'W:\\My Documents\\Master Voting History'\n",
    "surname_csv_file = r'W:\\My Documents\\Registration\\Names_2010Census.csv'\n",
    "historic_xlsx_file = r'W:\\My Documents\\historic-returns.xlsx'\n",
    "\n",
    "# Select elections of interest\n",
    "generals_list = '11/06/2018', '11/08/2016', '11/04/2014', '11/06/2012', 'NaN'\n",
    "primaries_list = '06/26/2018', '06/28/2016', '06/24/2014', '06/26/2012'\n",
    "\n",
    "# Crosstab data\n",
    "crosstab_criteria_list = ('PARTY', 'GENDER', 'PVP', 'PVG', 'VOTED_PARTY', 'TARGET','RACE', 'AGE_RANGE', 'CONGRESSIONAL', 'STATE_SENATE', \n",
    "                          'STATE_HOUSE', 'COUNTY')\n",
    "parties_list = ['REP', 'DEM', 'UAF']\n",
    "\n",
    "# Graph variables\n",
    "return_graph_file = r'W:\\My Documents\\2020_colorado_primary_ballot_trend.png'\n",
    "twitter_graph_file = r'W:\\My Documents\\2020_colorado_primary_twitter.png'\n",
    "uaf_break_file = r'W:\\My Documents\\2020_colorado_primary_uaf_break.png'\n",
    "im = Image.open(r'D:\\Users\\bengen343\\Documents\\Constellation Political\\Constellation Operations\\Graphics\\CPC Star in LIne.png')\n",
    "graph_time_str = (datetime.strftime(datetime.now(pytz.timezone('America/Denver')), '%Y-%m-%d %H:%M'))\n",
    "election_str = '2020 Colorado Primary'\n",
    "election_fname_str = '_'.join(election_str.split(' ')).lower()\n",
    "\n",
    "# Map variables\n",
    "map_shp_file = r'W:\\My Documents\\Counties84\\Counties84.shp'\n",
    "uaf_break_map_file = r'W:\\My Documents\\2020_colorado_primary_uaf_break_map.png'\n",
    "\n",
    "# Define colors for the various parties\n",
    "colors_dict = {'REP Low':(.996,.776,.773,0), 'REP High':(.412,.012,.004,0), \n",
    "               'DEM Low':(.773,.886,.996,0), 'DEM High':(.004,.216,.412,0), \n",
    "               'UAF Low':(.871,.773,.996,0), 'UAF High':(.188,.004,.412,0), \n",
    "               'TOT Low':(.949,.949,.949,0), 'TOT High':(.502,.502,.502,0)}\n",
    "\n",
    "web_colors_dict = {'REP Low':'#FEC6C5', 'REP High':'#D30803', \n",
    "               'DEM Low':'#C5E2FE', 'DEM High':'#036ED2', \n",
    "               'UAF Low':'#DEC5FE', 'UAF High':'#6103D3', \n",
    "               'TOT Low':'#FEDEC5', 'TOT High':'#D36103'}\n",
    "\n",
    "# Define colors for the various candidates\n",
    "rep_colors_dict = {'Boebert Low':(0.9294,0.6157,0.6314,0), 'Boebert High':(0.6235,0.1137,0.1333,0), \n",
    "                   'Tipton Low':(0.9412,0.6039,0.06353,0), 'Tipton High':(0.8235,0.1255,0.1882,0)}\n",
    "\n",
    "dem_colors_dict = {'Romanoff Low':(0.6275,0.7216,0.8471,0), 'Romanoff High':(0.2039,0.3294,0.4941,0), \n",
    "                   'Hickenlooper Low':(0.8078,0.7216,0.9333,0), 'Hickenlooper High':(0.2784,0.1255,0.5059,0)}\n",
    "\n",
    "# Define results variables\n",
    "dem_candidates_list = ['Andrew Romanoff', 'John W. Hickenlooper']\n",
    "rep_candidates_list = ['Lauren Boebert', 'Scott R. Tipton']\n",
    "result_county_str = 'Unnamed: 0'\n",
    "dem_result_tot_str = 'Unnamed: 6'\n",
    "rep_result_tot_str = 'Unnamed: 6'\n",
    "\n",
    "# Topline image variables\n",
    "font_file = r'W:\\My Documents\\Lato-Regular.ttf'\n",
    "\n",
    "# Excel output variables\n",
    "crosstabs_xlsx_file = r'W:\\My Documents\\2020COPrimaryBallotsCast.xlsx'\n",
    "facebook_csv_file = r'W:\\My Documents\\2020-co-primary-returned-fb.csv'\n",
    "rep_toplines_file = r'W:\\My Documents\\rep_toplines.png'\n",
    "dem_toplines_file = r'W:\\My Documents\\dem_toplines.png'\n",
    "uaf_toplines_file = r'W:\\My Documents\\uaf_toplines.png'\n",
    "\n",
    "# FTP variables  \n",
    "ftp_address = 'ftp.constellationpolitical.com'\n",
    "ftp_user = 'constel2'\n",
    "ftp_pass = 'Maelstrom343!'\n",
    "ftp_directory = '/public_html/ballots-co'\n",
    "ftp_local_directory = r'W:\\My Documents\\*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip return file\n",
    "zip_ref = zipfile.ZipFile(return_zip_file)\n",
    "zip_ref.extractall(return_local_directory)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import returned ballots to dataframe\n",
    "ballots_sent_df = pd.DataFrame()\n",
    "ballots_sent_df = pd.read_csv ((return_txt_file), sep=\"|\", encoding='cp437', \n",
    "                         index_col=None, header=0, low_memory=False, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target voters to dataframe\n",
    "target_df = pd.DataFrame()\n",
    "target_df = pd.read_csv ((target_csv_file), sep=\",\", encoding='cp437', \n",
    "                         index_col=None, header=0, low_memory=False, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that unifies the in-person & mail-in return vote dates\n",
    "ballots_sent_df['MAIL_BALLOT_RECEIVE_DATE'].fillna(ballots_sent_df['IN_PERSON_VOTE_DATE'], inplace=True)\n",
    "ballots_sent_df['RECEIVED'] = ballots_sent_df['MAIL_BALLOT_RECEIVE_DATE']\n",
    "\n",
    "# Narrow returned ballots frame to only those that have come back\n",
    "ballots_sent_df = ballots_sent_df[(ballots_sent_df['RECEIVED'].notnull())]\n",
    "\n",
    "# Output the number of rows/total voters\n",
    "print(\"Total Ballots Returned: {:,}\".format(len(ballots_sent_df)))\n",
    "\n",
    "# Narrow returned ballots data frame to only date returned and Voter ID\n",
    "ballots_sent_df = ballots_sent_df[['VOTER_ID', 'RECEIVED', 'VOTED_PARTY']]\n",
    "\n",
    "# Make the date of voting column formatting standardized\n",
    "ballots_sent_df['RECEIVED'] = pd.to_datetime(ballots_sent_df['RECEIVED']).dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Current Voter File\n",
    "print(\"Beginning to import current voter file at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "allFiles = glob.glob(voter_file_directory + \"/*.txt\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, sep=\",\", encoding='cp437', index_col=None, header=0, low_memory=False)\n",
    "    list_.append(df)\n",
    "voter_file_df = pd.concat(list_)\n",
    "\n",
    "voter_file_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Output the number registered voters\n",
    "print(\"Total Registration: {:,}\".format(len(voter_file_df)))\n",
    "print(\"Current registration file loaded at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join registration to returned ballots\n",
    "print(\"Matching votes cast to all registered voters...\")\n",
    "voter_file_df = pd.merge(voter_file_df, ballots_sent_df, on='VOTER_ID', how='left')\n",
    "\n",
    "# Replace minor party designations with 'OTH'\n",
    "voter_file_df.loc[((voter_file_df['PARTY'] != 'REP') & (voter_file_df['PARTY'] != 'DEM') & \n",
    "                  (voter_file_df['PARTY'] != 'UAF')), 'PARTY'] = 'OTH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vote history data frame\n",
    "print(\"Beginning to assemble vote history file at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "allFiles = glob.glob(voter_history_directory + \"/*.txt\")\n",
    "history_df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, sep=\",\", encoding='cp437', index_col=None, header=0, low_memory=False)\n",
    "    list_.append(df)\n",
    "history_df = pd.concat(list_)\n",
    "\n",
    "history_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Output the number of rows\n",
    "print(\"Vote History Records: {:,}\".format(len(history_df)))\n",
    "\n",
    "# Choose relevant elections for historic comparison\n",
    "class Contain:\n",
    "    def __init__(self, items):\n",
    "        self.items = set(items)\n",
    "    def __ne__(self, other):\n",
    "        return other not in self.items\n",
    "    def __eq__(self, other):\n",
    "        return other in self.items\n",
    "\n",
    "relevant = Contain(generals_list + primaries_list)\n",
    "\n",
    "# Relevant elections\n",
    "print(\"Narrowing vote history to relevant elections...\")\n",
    "# Limit to only relevant elections\n",
    "history_df = history_df[history_df['ELECTION_DATE'] == relevant]\n",
    "# Output the number of rows\n",
    "print(\"Relevant Election History Records: {0:,}\".format(len(history_df)))\n",
    "\n",
    "# Collapse history into single binary row\n",
    "print(\"Collapsing history into binary values...\")\n",
    "history_df = pd.get_dummies(history_df.set_index('VOTER_ID')['ELECTION_DATE'])\n",
    "history_df = history_df.reset_index().groupby('VOTER_ID').sum()\n",
    "history_df.reset_index(level=0, inplace=True)\n",
    "\n",
    "print(\"Finished assembling vote history file at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join registration to vote history\n",
    "print(\"Matching vote history to all registered voters...\")\n",
    "voter_file_df = pd.merge(voter_file_df, history_df, on='VOTER_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PVG Column\n",
    "print(\"Beginning to add PVG & PVP values at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "voter_file_df['REGISTRATION_DATE'] = pd.to_datetime(voter_file_df['REGISTRATION_DATE'], exact=False, errors='coerce')\n",
    "voter_file_df['PVG'] = 0\n",
    "\n",
    "last_date = pd.to_datetime('12/01/2018')\n",
    "\n",
    "voter_file_df['PVG'] = np.where(voter_file_df['REGISTRATION_DATE'] > last_date, 5,\n",
    "                                voter_file_df[generals_list[0]] + voter_file_df[generals_list[1]] +\n",
    "                                voter_file_df[generals_list[2]] + voter_file_df[generals_list[3]])\n",
    "\n",
    "# Add PVP Column\n",
    "voter_file_df['PVP'] = np.where(voter_file_df['REGISTRATION_DATE'] > last_date, 5,\n",
    "                                voter_file_df[primaries_list[0]] + voter_file_df[primaries_list[1]] +\n",
    "                                voter_file_df[primaries_list[2]] + voter_file_df[primaries_list[3]])\n",
    "\n",
    "voter_file_df['PVG'].fillna(0, inplace=True)\n",
    "voter_file_df['PVP'].fillna(0, inplace=True)\n",
    "\n",
    "voter_file_df['PVG'] = 'PVG' + voter_file_df['PVG'].astype('str')\n",
    "voter_file_df['PVP'] = 'PVP' + voter_file_df['PVP'].astype('str')\n",
    "\n",
    "print(\"Finished adding PVG & PVP values at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age ranges to registration\n",
    "print(\"Beginning to calculate age ranges at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "voter_file_df['AGE_RANGE'] = '0'\n",
    "voter_file_df.loc[(datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 62, 'AGE_RANGE'] = '>62'\n",
    "voter_file_df.loc[((datetime.now().year - voter_file_df['BIRTH_YEAR']) < 62) & \n",
    "                  ((datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 55), 'AGE_RANGE'] = '55-61'\n",
    "voter_file_df.loc[((datetime.now().year - voter_file_df['BIRTH_YEAR']) < 55) & \n",
    "                  ((datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 45), 'AGE_RANGE'] = '45-54'\n",
    "voter_file_df.loc[((datetime.now().year - voter_file_df['BIRTH_YEAR']) < 45) & \n",
    "                  ((datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 35), 'AGE_RANGE'] = '35-44'\n",
    "voter_file_df.loc[((datetime.now().year - voter_file_df['BIRTH_YEAR']) < 35) & \n",
    "                  ((datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 25), 'AGE_RANGE'] = '25-34'\n",
    "voter_file_df.loc[((datetime.now().year - voter_file_df['BIRTH_YEAR']) < 25) & \n",
    "                  ((datetime.now().year - voter_file_df['BIRTH_YEAR']) >= 18), 'AGE_RANGE'] = '18-24'\n",
    "\n",
    "print(\"Finished calculating age ranges at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add race classifier\n",
    "# Import Census Surname List\n",
    "print(\"Beginning to build race classifier at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "surnames_df = pd.DataFrame()\n",
    "surnames_df = pd.read_csv (surname_csv_file, sep=\",\", encoding='cp437',index_col=None, header=0, low_memory=False)\n",
    "\n",
    "# Convert percentages from strings to numbers\n",
    "surnames_df['pctwhite'] = pd.to_numeric(surnames_df['pctwhite'], errors='coerce')\n",
    "surnames_df['pcthispanic'] = pd.to_numeric(surnames_df['pcthispanic'], errors='coerce')\n",
    "surnames_df['pctblack'] = pd.to_numeric(surnames_df['pctblack'], errors='coerce')\n",
    "surnames_df['pctapi'] = pd.to_numeric(surnames_df['pctapi'], errors='coerce')\n",
    "\n",
    "# Assign a race classification where probability is over 80%\n",
    "surnames_df['RACE'] = 'norace'\n",
    "surnames_df.loc[surnames_df['pcthispanic'] >= 80, 'RACE'] = 'Hispanic'\n",
    "surnames_df.loc[surnames_df['pctblack'] >= 80, 'RACE'] = 'Black'\n",
    "surnames_df.loc[surnames_df['pctapi'] >= 80, 'RACE'] = 'Asian'\n",
    "surnames_df.loc[surnames_df['pctwhite'] >= 80, 'RACE'] = 'White'\n",
    "\n",
    "# Purge irrelevant columns from surnames\n",
    "surnames_df = surnames_df[['name','RACE']]\n",
    "surnames_df.rename(columns={'name':'LAST_NAME'}, inplace=True)\n",
    "\n",
    "# Join surnames to master history\n",
    "print(\"Matching race against all registered voters...\")\n",
    "voter_file_df = pd.merge(voter_file_df, surnames_df, on='LAST_NAME', how='left')\n",
    "\n",
    "# Output the number of total votes cast\n",
    "print(\"Total Registered Voters: {:,}\".format(len(voter_file_df)))\n",
    "print(\"Finished building race classifier at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge target voter designation into the file\n",
    "voter_file_df = pd.merge(voter_file_df, target_df, on='VOTER_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output to upload to Facebook\n",
    "print(\"Beginning to build Facebook purge list at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "# Narrow to the relevant columns of those who have returned ballots\n",
    "facebook_df = voter_file_df[voter_file_df['PARTY'] != 'DEM']\n",
    "facebook_df = facebook_df[facebook_df['RECEIVED'].notnull()][['PHONE_NUM', 'FIRST_NAME', 'LAST_NAME', \n",
    "                                                              'RESIDENTIAL_ZIP_CODE', 'RESIDENTIAL_CITY', \n",
    "                                                              'RESIDENTIAL_STATE', 'BIRTH_YEAR', 'GENDER']]\n",
    "\n",
    "# Fix the formatting of the phone numbers so Facebook can understand\n",
    "facebook_df['PHONE_NUM'] = facebook_df['PHONE_NUM'].astype('str').apply(lambda x: ''.join(i for i in x if i.isdigit()))\n",
    "facebook_df['PHONE_NUM'] = facebook_df['PHONE_NUM'].astype('str').apply(lambda x: '1-(' + x[:3] + ')-' + x[3:6] + '-' + x[6:10])\n",
    "\n",
    "# Format genders so that Facebook likes them\n",
    "facebook_df['GENDER'] = facebook_df['GENDER'].apply(lambda x: x[:1])\n",
    "\n",
    "# Rename columns so they match what Facebook is expecting\n",
    "facebook_df.columns = ['phone', 'fn', 'ln', 'zip', 'ct', 'st', 'doby', 'gen']\n",
    "facebook_df['country'] = 'US'\n",
    "\n",
    "# Export the facebook purge list to a csv\n",
    "facebook_df.to_csv(facebook_csv_file)\n",
    "\n",
    "print(\"Finished building Facebook purge list at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export lists of those who have returned ballots for target races/clients\n",
    "target_returns_dict = {}\n",
    "for geography in target_geographies_dict.keys():\n",
    "    target_returns_dict[geography] = voter_file_df[(voter_file_df[target_geographies_dict.get(geography)] == geography) & \n",
    "                                                   (voter_file_df['RECEIVED'].notnull())][['VOTER_ID', 'PRECINCT', \n",
    "                                                                                           'LAST_NAME', 'FIRST_NAME', \n",
    "                                                                                           'PARTY', 'VOTED_PARTY', \n",
    "                                                                                           'GENDER', 'BIRTH_YEAR', \n",
    "                                                                                           'PHONE_NUM','RESIDENTIAL_ADDRESS', \n",
    "                                                                                           'RESIDENTIAL_CITY', \n",
    "                                                                                           'RESIDENTIAL_STATE', \n",
    "                                                                                           'RESIDENTIAL_ZIP_CODE', \n",
    "                                                                                           'RESIDENTIAL_ZIP_PLUS', \n",
    "                                                                                           'MAIL_ADDR1', \n",
    "                                                                                           'MAIL_ADDR2', 'MAIL_ADDR3', \n",
    "                                                                                           'MAILING_CITY', 'MAILING_STATE', \n",
    "                                                                                           'MAILING_ZIP_CODE']]\n",
    "    target_returns_dict[geography].to_csv(r'W:\\My Documents\\\\' + geography + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow voter filedataframe to only data of interest\n",
    "voter_file_df = voter_file_df[['VOTER_ID', 'PARTY', 'GENDER', 'PVP', 'PVG', 'VOTED_PARTY', 'TARGET','RACE', 'AGE_RANGE',\n",
    "                               'CONGRESSIONAL', 'STATE_SENATE', 'STATE_HOUSE', 'COUNTY', 'PRECINCT', 'RESIDENTIAL_CITY', \n",
    "                               'RECEIVED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values for UAF vote choice so they don't conflict with party affiliation\n",
    "for party in voter_file_df['VOTED_PARTY'].unique():\n",
    "    if not pd.isnull(party):\n",
    "        voter_file_df.loc[voter_file_df['VOTED_PARTY'] == party, 'VOTED_PARTY'] = ('Voted ' + party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that shows the daily returns by various crosstab criteria\n",
    "print(\"Commencing creation of timing return dataframe %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "timing_crosstabs_df = pd.DataFrame()\n",
    "\n",
    "for item in crosstab_criteria_list:\n",
    "    timing_crosstabs_df = pd.concat([timing_crosstabs_df, pd.crosstab(voter_file_df['RECEIVED'], \n",
    "                                                                      voter_file_df[item], margins=True)], \n",
    "                                    axis=1, sort=True)\n",
    "\n",
    "timing_crosstabs_df = timing_crosstabs_df[timing_crosstabs_df.index != 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of cumulative returns for the parties of interest\n",
    "timing_cumulative_df = pd.DataFrame()\n",
    "timing_cumulative_df['RECEIVED'] = timing_crosstabs_df.index\n",
    "\n",
    "for party in parties_list:\n",
    "    timing_cumulative_df[party] = timing_crosstabs_df[party].cumsum().to_list()\n",
    "    \n",
    "timing_cumulative_df['RECEIVED'] = pd.to_datetime(timing_cumulative_df['RECEIVED'], exact=False, errors='coerce')\n",
    "\n",
    "print(\"Finished timing return dataframe at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file of historic returns and create a dictionary of dataframes for the different years\n",
    "historic_returns_xlsx = pd.ExcelFile(historic_xlsx_file)\n",
    "historic_returns_dict = {sheet:historic_returns_xlsx.parse(sheet) for sheet in historic_returns_xlsx.sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index for the earliest date available in the historic data\n",
    "i = timing_cumulative_df[timing_cumulative_df['RECEIVED'] == historic_returns_dict.get(historic_returns_xlsx.sheet_names[0]).loc[0, 'RECEIVED']].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow the current cumulative sum dataframe to the same window as the historic returns\n",
    "timing_cumulative_df = timing_cumulative_df[i:]\n",
    "timing_cumulative_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative advantage for this year and add it as a column\n",
    "for i in timing_cumulative_df.index:\n",
    "    timing_cumulative_df.loc[i, 'Cum Adv'] = ((timing_cumulative_df.loc[i, 'REP'] - timing_cumulative_df.loc[i, 'DEM']) / \n",
    "                                              timing_cumulative_df.loc[i, parties_list].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the current columns so we can distinguish them after the merge\n",
    "columns_list = ['RECEIVED']\n",
    "for column in timing_cumulative_df.columns[1:]:\n",
    "    columns_list.append('Current ' + column)\n",
    "    \n",
    "timing_cumulative_df.columns = columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marry the current data into each of the historic dataframes\n",
    "for key in historic_returns_dict.keys():\n",
    "    historic_returns_dict[key] = pd.merge(historic_returns_dict.get(key), timing_cumulative_df, how='left', on='RECEIVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Populate forecasts using the historic data for each frame\n",
    "for key in historic_returns_dict.keys():\n",
    "    for party in parties_list:\n",
    "        for i in historic_returns_dict.get(key).index[1:]:\n",
    "            if historic_returns_dict.get(key).loc[i-1, 'RECEIVED'] >= pd.to_datetime(datetime.today().date()):\n",
    "                historic_returns_dict.get(key).loc[i, 'Forecast ' + party] = (historic_returns_dict.get(key).loc[i, party] * (historic_returns_dict.get(key).loc[i-1, 'Forecast ' + party] / historic_returns_dict.get(key).loc[i-1, party]))\n",
    "            else:\n",
    "                historic_returns_dict.get(key).loc[i, 'Forecast ' + party] = (historic_returns_dict.get(key).loc[i, party] * (historic_returns_dict.get(key).loc[i-1, 'Current ' + party] / historic_returns_dict.get(key).loc[i-1, party]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute value of the errors in the forecasts\n",
    "for key in historic_returns_dict.keys():\n",
    "    for i in historic_returns_dict.get(key)[historic_returns_dict.get(key)['RECEIVED'] < pd.to_datetime(datetime.today().date())].index:\n",
    "        error_float = 0\n",
    "        for party in parties_list:\n",
    "            error_float += (historic_returns_dict.get(key).loc[i, 'Current ' + party] - historic_returns_dict.get(key).loc[i, 'Forecast ' + party])**2\n",
    "        historic_returns_dict.get(key).loc[i, 'Error'] = error_float\n",
    "    historic_returns_dict.get(key)['Error'] = historic_returns_dict.get(key)['Error'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate a dictionary with the cumulative forecast errors through today\n",
    "today_index = max(historic_returns_dict.get(key)[historic_returns_dict.get(key)['RECEIVED'] < pd.to_datetime(datetime.today().date())].index)\n",
    "errors_dict = {}\n",
    "for sheet in historic_returns_xlsx.sheet_names:\n",
    "    errors_dict[sheet] = historic_returns_dict.get(sheet).loc[today_index, 'Error']\n",
    "\n",
    "# Select the best perfoming year\n",
    "comp_year_str = min(errors_dict.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "# Use the best comparison for our forecast\n",
    "timing_cumulative_df = historic_returns_dict.get(comp_year_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_year_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch any ballots that came in after Election Day and add them in to the Election Day total\n",
    "for party in parties_list:\n",
    "    timing_cumulative_df.loc[max(timing_cumulative_df.index), 'Current ' + party] = timing_crosstabs_df[party].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating graphics %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "#timing_cumulative_df['PLOT_DATE'] = timing_cumulative_df['RECEIVED'].apply(lambda x: dates.date2num(datetime.strptime(x,'%m/%d/%Y')))\n",
    "timing_cumulative_df['PLOT_DATE'] = timing_cumulative_df['RECEIVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph of Statewide ballot returns actual\n",
    "# decreases width and height of the watermark\n",
    "im = im.resize((2000,2000))\n",
    "\n",
    "# Define the size of the plot area\n",
    "fig, ax1 = plt.subplots(figsize=(12,6.3), dpi=300)\n",
    "\n",
    "# Add a secondary access\n",
    "# ax2 = ax1.twinx()\n",
    "\n",
    "#Establish DF range to plot, in this case three weeks out from election\n",
    "x_max = len(timing_cumulative_df)\n",
    "x_min = 3\n",
    "\n",
    "# Plot various time series lines for actuals and forecasts on y-axis 1\n",
    "for party in parties_list:\n",
    "    ax1.plot(timing_cumulative_df.loc[x_min:x_max]['PLOT_DATE'], timing_cumulative_df.loc[x_min:x_max]['Forecast ' + party], color=web_colors_dict.get(party + ' Low'), label= party + ' Forecast', zorder=2)\n",
    "    ax1.plot(timing_cumulative_df.loc[x_min:x_max]['PLOT_DATE'], timing_cumulative_df.loc[x_min:x_max]['Current ' + party], color=web_colors_dict.get(party + ' High'), label= party + ' Actual', zorder=5)\n",
    "    \n",
    "# Plot various time series lines for actuals and forecasts on y-axis 2\n",
    "# ax2.plot(forecast_df.loc[x_min:x_max]['RECEIVED'], forecast_df.loc[x_min:x_max]['RTLA Forecast'], color='#808080', label='RTLA Forecast', linewidth=2.0)\n",
    "\n",
    "# Set the labels and formatting for y-axis 1\n",
    "ax1.set_ylabel('Cumulative Ballots Returned', fontname='Lato', fontsize='14')      \n",
    "ax1.yaxis.grid(which=\"major\")\n",
    "ax1.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# Set the labels and formatting for y-axis 2\n",
    "# ax2.set_ylabel('RTLA', fontname='Lato', fontsize='14')      \n",
    "# ax2.set_yticklabels(['{:,.0%}'.format(x) for x in (ax2.get_yticks())])\n",
    "\n",
    "# Define legends for both axes\n",
    "ax1.legend(loc='upper left', fontsize='14')\n",
    "# ax2.legend(loc='lower right', fontsize='14')\n",
    "\n",
    "# Set x axes formatting\n",
    "ax1.set_xlabel('Date', fontname='Lato', fontsize='14')\n",
    "ax1.set_xticklabels(ax1.get_xticks(),rotation=90, fontsize=14)\n",
    "ax1.xaxis.set_major_locator(dates.DayLocator(interval=1))\n",
    "ax1.xaxis.set_major_formatter(dates.DateFormatter('%m-%d'))\n",
    "\n",
    "# Set watermark and overall graphic formatting\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.suptitle(election_str + ' Ballot Returns', fontname='Lato', fontsize='24')\n",
    "plt.figimage(im, 760, 50, alpha=0.20, zorder=3)\n",
    "plt.figtext(0.5, 0.910, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', \n",
    "            fontsize='14',color='#686C6D')\n",
    "plt.figtext(0.5, 0.885, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(return_graph_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph of UAF break toward parties\n",
    "# decreases width and height of the watermark\n",
    "im = im.resize((1000,1000))\n",
    "\n",
    "# Define the size of the plot area\n",
    "plt.figure(figsize=(6,6), dpi=300)\n",
    "ax = plt.axes()\n",
    "\n",
    "# Plot various time series lines for actuals and forecasts on y-axis 1\n",
    "ax.pie(timing_crosstabs_df[['Voted DEM', 'Voted REP']].sum().to_list(), labels=['DEM', 'REP'], colors=['#036ED2', '#D30803'], autopct='%1.1f%%')\n",
    "\n",
    "# Set x axes formatting\n",
    "ax.axis('equal')\n",
    "\n",
    "# Set watermark and overall graphic formatting\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.suptitle('UAF Party Choice', fontname='Lato', fontsize='24')\n",
    "plt.figimage(im, 375, 350, alpha=0.20, zorder=3)\n",
    "plt.figtext(0.5, 0.910, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', \n",
    "            fontsize='14',color='#686C6D')\n",
    "plt.figtext(0.5, 0.010, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(uaf_break_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose fullscope registration crosstabs\n",
    "print(\"Building registration crosstabs at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "registration_crosstabs_df = pd.DataFrame()\n",
    "\n",
    "for vertical in crosstab_criteria_list:\n",
    "    horizontal_df = pd.DataFrame()\n",
    "    for horizontal in crosstab_criteria_list:\n",
    "        horizontal_df = pd.concat([horizontal_df, pd.crosstab(voter_file_df[vertical], voter_file_df[horizontal], \n",
    "                                                              margins=True)], axis=1, sort=True)\n",
    "        del horizontal_df['All']\n",
    "    registration_crosstabs_df = pd.concat([registration_crosstabs_df, horizontal_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the precinct crosstabs only to the vertical crosstab axis\n",
    "horizontal_df = pd.DataFrame()\n",
    "for horizontal in crosstab_criteria_list:\n",
    "    horizontal_df = pd.concat([horizontal_df, pd.crosstab(voter_file_df['PRECINCT'], voter_file_df[horizontal], \n",
    "                                                          margins=True)], axis=1, sort=True)\n",
    "    del horizontal_df['All']\n",
    "    \n",
    "registration_crosstabs_df = pd.concat([registration_crosstabs_df, horizontal_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the total columns and rows\n",
    "registration_crosstabs_df = registration_crosstabs_df[registration_crosstabs_df.index != 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new frame with only those individuals who have voted\n",
    "ballots_cast_df = voter_file_df[voter_file_df['RECEIVED'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose fullscope ballots cast crosstabs\n",
    "print(\"Composing ballots cast crosstabs at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "ballots_crosstabs_df = pd.DataFrame()\n",
    "\n",
    "for vertical in crosstab_criteria_list:\n",
    "    horizontal_df = pd.DataFrame()\n",
    "    for horizontal in crosstab_criteria_list:\n",
    "        horizontal_df = pd.concat([horizontal_df, pd.crosstab(ballots_cast_df[vertical], ballots_cast_df[horizontal], \n",
    "                                                              margins=True)], axis=1, sort=True)\n",
    "        del horizontal_df['All']\n",
    "    ballots_crosstabs_df = pd.concat([ballots_crosstabs_df, horizontal_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the precinct crosstabs only to the vertical crosstab axis\n",
    "horizontal_df = pd.DataFrame()\n",
    "for horizontal in crosstab_criteria_list:\n",
    "    horizontal_df = pd.concat([horizontal_df, pd.crosstab(ballots_cast_df['PRECINCT'], ballots_cast_df[horizontal], \n",
    "                                                          margins=True)], axis=1, sort=True)\n",
    "    del horizontal_df['All']\n",
    "    \n",
    "ballots_crosstabs_df = pd.concat([ballots_crosstabs_df, horizontal_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the total columns and rows\n",
    "ballots_crosstabs_df = ballots_crosstabs_df[ballots_crosstabs_df.index != 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a dataframe for turnout\n",
    "print(\"Composing turnout crosstabs at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "turnout_crosstabs_df = ballots_crosstabs_df / registration_crosstabs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe into an order that matches the other crosstab reports\n",
    "for i in turnout_crosstabs_df.index:\n",
    "    turnout_crosstabs_df.loc[i, 'SORT'] = np.where(registration_crosstabs_df.index == i)[0]\n",
    "\n",
    "turnout_crosstabs_df = turnout_crosstabs_df.sort_values('SORT')\n",
    "del turnout_crosstabs_df['SORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dateframe for map data and pull in the county registration totals for each party\n",
    "print(\"Creating maps at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "map_data_df = pd.DataFrame()\n",
    "\n",
    "map_data_df = registration_crosstabs_df.loc['Adams':'Yuma'][['REP', 'DEM', 'UAF', 'OTH']]\n",
    "\n",
    "map_data_df.rename(columns={'REP':'Registration REP'}, inplace=True)\n",
    "map_data_df.rename(columns={'DEM':'Registration DEM'}, inplace=True)\n",
    "map_data_df.rename(columns={'UAF':'Registration UAF'}, inplace=True)\n",
    "map_data_df.rename(columns={'OTH':'Registration OTH'}, inplace=True)\n",
    "\n",
    "map_data_df.reset_index(level=0, inplace=True)\n",
    "\n",
    "map_data_df.rename(columns={'index':'COUNTY'}, inplace=True)\n",
    "\n",
    "map_data_df['COUNTY'] = map_data_df['COUNTY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of ballots cast info by county\n",
    "map_cast_df = pd.DataFrame()\n",
    "\n",
    "map_cast_df = ballots_crosstabs_df.loc['Adams':'Yuma'][['REP', 'DEM', 'UAF', 'OTH']]\n",
    "\n",
    "map_cast_df.rename(columns={'REP':'Cast REP'}, inplace=True)\n",
    "map_cast_df.rename(columns={'DEM':'Cast DEM'}, inplace=True)\n",
    "map_cast_df.rename(columns={'UAF':'Cast UAF'}, inplace=True)\n",
    "map_cast_df.rename(columns={'OTH':'Cast OTH'}, inplace=True)\n",
    "\n",
    "map_cast_df['index'] = map_cast_df.index\n",
    "\n",
    "for i in map_cast_df.index:\n",
    "    map_cast_df.loc[i, 'COUNTY'] = (map_cast_df.loc[i, 'index'].upper())\n",
    "    \n",
    "del map_cast_df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a a dataframe of the UAF break by county\n",
    "uaf_break_df = pd.DataFrame()\n",
    "\n",
    "uaf_break_df = ballots_crosstabs_df.loc['Adams':'Yuma'][['Voted REP', 'Voted DEM']]\n",
    "uaf_break_df['Voted REP %'] = uaf_break_df['Voted REP'] / (uaf_break_df['Voted REP'] + uaf_break_df['Voted DEM'])\n",
    "uaf_break_df['Voted DEM %'] = uaf_break_df['Voted DEM'] / (uaf_break_df['Voted REP'] + uaf_break_df['Voted DEM'])\n",
    "\n",
    "uaf_break_df['index'] = map_cast_df.index\n",
    "\n",
    "for i in uaf_break_df.index:\n",
    "    uaf_break_df.loc[i, 'COUNTY'] = (uaf_break_df.loc[i, 'index'].upper())\n",
    "    \n",
    "del uaf_break_df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes for mapping\n",
    "map_data_df = pd.merge(map_data_df, map_cast_df, on='COUNTY', how='left')\n",
    "map_data_df = pd.merge(map_data_df, uaf_break_df, on='COUNTY', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add turnout calculations to map dataframe\n",
    "parties_list = ['REP', 'DEM', 'UAF']\n",
    "\n",
    "for party in parties_list:\n",
    "    map_data_df['Turnout ' + party] = map_data_df['Cast ' + party] / map_data_df['Registration ' + party]\n",
    "    \n",
    "# Total turnout\n",
    "map_data_df['Turnout TOT'] = ((map_data_df['Cast REP'] + map_data_df['Cast DEM'] + map_data_df['Cast UAF'] \n",
    "                              + map_data_df['Cast OTH']) / (map_data_df['Registration REP'] \n",
    "                                                            + map_data_df['Registration DEM'] \n",
    "                                                            + map_data_df['Registration UAF'] \n",
    "                                                           + map_data_df['Registration OTH']))\n",
    "\n",
    "# Add column for total votes cast in each county\n",
    "map_data_df['Cast TOT'] = (map_data_df['Cast REP'] + map_data_df['Cast DEM'] + map_data_df['Cast UAF'] \n",
    "                          + map_data_df['Cast OTH'])\n",
    "\n",
    "map_data_df = map_data_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to make custom colormaps\n",
    "def make_colormap(seq):\n",
    "    \"\"\"Return a LinearSegmentedColormap\n",
    "    seq: a sequence of floats and RGB-tuples. The floats should be increasing\n",
    "    and in the interval (0,1).\n",
    "    \"\"\"\n",
    "    seq = [(None,) * 3, 0.0] + list(seq) + [1.0, (None,) * 3]\n",
    "    cdict = {'red': [], 'green': [], 'blue': []}\n",
    "    for i, item in enumerate(seq):\n",
    "        if isinstance(item, float):\n",
    "            r1, g1, b1 = seq[i - 1]\n",
    "            r2, g2, b2 = seq[i + 1]\n",
    "            cdict['red'].append([item, r1, r2])\n",
    "            cdict['green'].append([item, g1, g2])\n",
    "            cdict['blue'].append([item, b1, b2])\n",
    "    return mcolors.LinearSegmentedColormap('CustomMap', cdict)\n",
    "\n",
    "c = mcolors.ColorConverter().to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TOT to the parties list for mapping iterations\n",
    "parties_list.append('TOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the turnout\n",
    "# Define custom colormap\n",
    "for party in parties_list:\n",
    "    \n",
    "    # Define colors to use with the party at hand\n",
    "    rvb = make_colormap([c(colors_dict[party + ' Low']), c(colors_dict[party + ' High'])])\n",
    "    \n",
    "    # Initiate the plot for the map\n",
    "    f, ax = plt.subplots(figsize=(13,15), dpi=300)\n",
    "    \n",
    "    # Load the shapefile map of Colorado counties\n",
    "    colorado_map = gpd.GeoDataFrame.from_file(map_shp_file)\n",
    "    \n",
    "    # Merge the turnout data into the map\n",
    "    colorado_map = colorado_map.merge(map_data_df, on='COUNTY')\n",
    "    \n",
    "    colorado_map['coords'] = colorado_map['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    colorado_map['coords'] = [coords[0] for coords in colorado_map['coords']]\n",
    "    \n",
    "    # Plot turnout for the party at hand\n",
    "    colorado_map.plot(ax=ax, column='Turnout ' + party, cmap=rvb, linewidth=0.5, edgecolor='0.5')\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(election_str + '-' + party + ' Turnout', fontname='Lato', fontsize='24')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Format the labels\n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=row['COUNTY'], xy=row['coords'], horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "        \n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=(\"{0:.1f}%\".format(row['Turnout ' + party] * 100)), xy=row['coords'], \n",
    "                     textcoords='offset points', xytext=(0,-10), horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "    \n",
    "    #Add watermark and webpage\n",
    "    im = im.resize((2000,2000))\n",
    "    plt.figimage(im, 1000, 150, alpha=0.20, zorder=3)\n",
    "    plt.figtext(0.5, 0.739, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', fontsize='14', \n",
    "                color='#686C6D')\n",
    "    plt.figtext(0.5, 0.725, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "    \n",
    "    # Export to image file\n",
    "    plt.savefig(r'W:\\My Documents\\\\' + election_fname_str + '_' + party + '_turnout_map.png', \n",
    "                pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map total ballots cast\n",
    "for party in parties_list:\n",
    "    \n",
    "    # Define colors to use with the party at hand\n",
    "    rvb = make_colormap([c(colors_dict[party + ' Low']), c(colors_dict[party + ' High'])])\n",
    "    \n",
    "    # Initiate the plot for the map\n",
    "    f, ax = plt.subplots(figsize=(13,15), dpi=300)\n",
    "    \n",
    "    # Load the shapefile map of Colorado counties\n",
    "    colorado_map = gpd.GeoDataFrame.from_file(map_shp_file)\n",
    "    \n",
    "    # Merge the turnout data into the map\n",
    "    colorado_map = colorado_map.merge(map_data_df, on='COUNTY')\n",
    "    \n",
    "    colorado_map['coords'] = colorado_map['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    colorado_map['coords'] = [coords[0] for coords in colorado_map['coords']]\n",
    "    \n",
    "    # Plot turnout for the party at hand\n",
    "    colorado_map.plot(ax=ax, column='Cast ' + party, cmap=rvb, linewidth=0.5, edgecolor='0.5')\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(election_str + '-' + party + ' Ballots Cast', fontname='Lato', fontsize='24')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Format the labels\n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=row['COUNTY'], xy=row['coords'], horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "        \n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=(\"{:,.0f}\".format(row['Cast ' + party])), xy=row['coords'], \n",
    "                     textcoords='offset points', xytext=(0,-10), horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "    \n",
    "    #Add watermark and webpage\n",
    "    im = im.resize((2000,2000))\n",
    "    plt.figimage(im, 1000, 150, alpha=0.20, zorder=3)\n",
    "    plt.figtext(0.5, 0.739, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', fontsize='14', \n",
    "                color='#686C6D')\n",
    "    plt.figtext(0.5, 0.725, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "    \n",
    "    # Export to image file\n",
    "    plt.savefig(r'W:\\My Documents\\\\' + election_fname_str + '_' + party + '_cast_map.png', pad_inches=0, \n",
    "                bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map UAF partisan break\n",
    "# Define custom colormap\n",
    "rvb = make_colormap(\n",
    "    [c((.003,.216,.412,0)), c((.773,.886,.996,0)), 0.5, c((.996,.776,.773,0)), c((.412,.012,.004,0))])\n",
    "\n",
    "# Initiate map plot\n",
    "f, ax = plt.subplots(figsize=(13,15), dpi=300)\n",
    "\n",
    "colorado_map = gpd.GeoDataFrame.from_file(map_shp_file)\n",
    "\n",
    "colorado_map = colorado_map.merge(map_data_df, on='COUNTY')\n",
    "\n",
    "colorado_map['coords'] = colorado_map['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "colorado_map['coords'] = [coords[0] for coords in colorado_map['coords']]\n",
    "\n",
    "colorado_map.plot(ax=ax, column='Voted REP %', cmap=rvb, linewidth=0.5, edgecolor='0.5')\n",
    "ax.set_axis_off()\n",
    "ax.set_title(election_str + ' UAF Break Toward REP', fontname='Lato', fontsize='24')\n",
    "plt.tight_layout()\n",
    "\n",
    "for idx, row in colorado_map.iterrows():\n",
    "    plt.annotate(s=row['COUNTY'], xy=row['coords'], horizontalalignment='center', \n",
    "                 fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "    \n",
    "for idx, row in colorado_map.iterrows():\n",
    "    plt.annotate(s=(\"{0:.1f}%\".format(row['Voted REP %'] * 100)), xy=row['coords'], textcoords='offset points', \n",
    "                 xytext=(0,-10), horizontalalignment='center', \n",
    "                 fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "\n",
    "im = im.resize((2000,2000))\n",
    "plt.figimage(im, 1000, 150, alpha=0.20, zorder=3)\n",
    "plt.figtext(0.5, 0.739, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', fontsize='14', \n",
    "                color='#686C6D')\n",
    "plt.figtext(0.5, 0.725, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "    \n",
    "plt.savefig(uaf_break_map_file, pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make thumbnails out of the larger images\n",
    "for item in glob.glob(ftp_local_directory):\n",
    "    if ((os.path.isfile(item)) & ('thumb' not in item)):\n",
    "        im = Image.open(item)\n",
    "        f, e = os.path.splitext(item)\n",
    "        imResize = im.resize((int(im.size[0]/6),int(im.size[1]/6)), Image.ANTIALIAS)\n",
    "        imResize.save(f + '_thumb.png', 'PNG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Commencing headline graphic creation at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "img = Image.new('RGB', (290, 93), color = (254, 198, 197))\n",
    " \n",
    "fnt = ImageFont.truetype(font_file, 11*2)\n",
    "d = ImageDraw.Draw(img)\n",
    "d.text((5,10), 'REP Ballots Cast: {0:,.0f}'.format(map_data_df['Cast REP'].sum()), font=fnt, fill=(105, 1, 1))\n",
    "d.text((5,35), 'REP Turnout: {0:.1f}%'.format((map_data_df['Cast REP'].sum()/map_data_df['Registration REP'].sum())*100), font=fnt, fill=(105, 1, 1))\n",
    "d.text((5,60), 'REP Contribution: {0:.1f}%'.format((map_data_df['Cast REP'].sum()/(map_data_df['Cast REP'].sum() + map_data_df['Cast DEM'].sum() + map_data_df['Cast UAF'].sum() + map_data_df['Cast OTH'].sum()))*100), font=fnt, fill=(105, 1, 1))\n",
    "\n",
    "img.save(rep_toplines_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.new('RGB', (290, 93), color = (197, 226, 254))\n",
    " \n",
    "fnt = ImageFont.truetype(font_file, 11*2)\n",
    "d = ImageDraw.Draw(img)\n",
    "d.text((5,10), 'DEM Ballots Cast: {0:,.0f}'.format(map_data_df['Cast DEM'].sum()), font=fnt, fill=(1, 55, 105))\n",
    "d.text((5,35), 'DEM Turnout: {0:.1f}%'.format((map_data_df['Cast DEM'].sum()/map_data_df['Registration DEM'].sum())*100), font=fnt, fill=(1, 55, 105))\n",
    "d.text((5,60), 'DEM Contribution: {0:.1f}%'.format((map_data_df['Cast DEM'].sum()/(map_data_df['Cast REP'].sum() + map_data_df['Cast DEM'].sum() + map_data_df['Cast UAF'].sum() + map_data_df['Cast OTH'].sum()))*100), font=fnt, fill=(1, 55, 105))\n",
    "\n",
    "img.save(dem_toplines_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.new('RGB', (290, 93), color = (222, 197, 254))\n",
    " \n",
    "fnt = ImageFont.truetype(font_file, 11*2)\n",
    "d = ImageDraw.Draw(img)\n",
    "d.text((5,10), 'UAF Ballots Cast: {0:,.0f}'.format(map_data_df['Cast UAF'].sum()), font=fnt, fill=(48, 1, 105))\n",
    "d.text((5,35), 'UAF Turnout: {0:.1f}%'.format((map_data_df['Cast UAF'].sum()/map_data_df['Registration UAF'].sum())*100), font=fnt, fill=(48, 1, 105))\n",
    "d.text((5,60), 'UAF Contribution: {0:.1f}%'.format((map_data_df['Cast UAF'].sum()/(map_data_df['Cast REP'].sum() + map_data_df['Cast DEM'].sum() + map_data_df['Cast UAF'].sum() + map_data_df['Cast OTH'].sum()))*100), font=fnt, fill=(48, 1, 105))\n",
    "\n",
    "img.save(uaf_toplines_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ballots cast to Excel\n",
    "writer = pd.ExcelWriter(crosstabs_xlsx_file, engine='xlsxwriter')\n",
    "timing_crosstabs_df.to_excel(writer, 'ReturnTiming')\n",
    "registration_crosstabs_df.to_excel(writer, 'RegistrationCrosstabs')\n",
    "ballots_crosstabs_df.to_excel(writer, 'CastCrosstabs')\n",
    "turnout_crosstabs_df.to_excel(writer, 'TurnoutCrosstabs')\n",
    "writer.save()\n",
    "print(\"Excel Export Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplines = [Image.open(x) for x in [rep_toplines_file, dem_toplines_file, uaf_toplines_file]]\n",
    "graph = Image.open(return_graph_file)\n",
    "\n",
    "graph_new = graph.resize((int(toplines[0].size[0]*3), int(((toplines[0].size[0]*3)/graph.size[0])*graph.size[1])), Image.ANTIALIAS)\n",
    "\n",
    "total_width = graph_new.size[0]\n",
    "total_height = graph_new.size[1] + toplines[0].size[1]\n",
    "\n",
    "twitter_im = Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "x_offset = int((graph_new.size[0] - (toplines[0].size[0]*3))/2)\n",
    "\n",
    "for im in toplines:\n",
    "  twitter_im.paste(im, (x_offset,0))\n",
    "  x_offset += im.size[0]\n",
    "\n",
    "twitter_im.paste(graph_new, (0,toplines[0].size[1]))\n",
    "\n",
    "twitter_im.save(twitter_graph_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = FTP(ftp_address)\n",
    "ftp.login(ftp_user, ftp_pass)\n",
    "ftp.cwd(ftp_directory)\n",
    "\n",
    "for fname in glob.glob(ftp_local_directory):\n",
    "    with open(fname, 'rb') as f:  \n",
    "        ftp.storbinary('STOR %s' % os.path.basename(fname), f)\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakout crosstabs for other target districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of target dataframes\n",
    "target_dataframes_dict = {}\n",
    "for geography in target_geographies_dict.keys():\n",
    "    target_dataframes_dict[geography + ' Registration'] = voter_file_df[voter_file_df[target_geographies_dict.get(geography)] == geography]\n",
    "    target_dataframes_dict[geography + ' Ballots Cast'] = ballots_cast_df[ballots_cast_df[target_geographies_dict.get(geography)] == geography]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose fullscope registration crosstabs\n",
    "print(\"Building target district registration crosstabs at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "for geography in target_geographies_dict.keys():\n",
    "    target_dataframes_dict[geography + ' Registration Crosstabs'] = pd.DataFrame()\n",
    "    \n",
    "    for vertical in crosstab_criteria_list:\n",
    "        horizontal_df = pd.DataFrame()\n",
    "        for horizontal in crosstab_criteria_list:\n",
    "            try:\n",
    "                horizontal_df = pd.concat([horizontal_df, pd.crosstab(target_dataframes_dict.get(geography + ' Registration')[vertical], target_dataframes_dict.get(geography + ' Registration')[horizontal], margins=True)], axis=1, sort=True)\n",
    "                del horizontal_df['All']\n",
    "            except:\n",
    "                print(geography + horizontal)\n",
    "        target_dataframes_dict[geography + ' Registration Crosstabs'] = pd.concat([target_dataframes_dict.get(geography + ' Registration Crosstabs'), horizontal_df], axis=0, sort=False)\n",
    "    \n",
    "    # Add the precinct crosstabs only to the vertical crosstab axis\n",
    "    horizontal_df = pd.DataFrame()\n",
    "    for horizontal in crosstab_criteria_list:\n",
    "        try:\n",
    "            horizontal_df = pd.concat([horizontal_df, pd.crosstab(target_dataframes_dict.get(geography + ' Registration')['PRECINCT'], target_dataframes_dict.get(geography + ' Registration')[horizontal], margins=True)], axis=1, sort=True)\n",
    "            del horizontal_df['All']\n",
    "        except:\n",
    "            print(geography + horizontal)\n",
    "    target_dataframes_dict[geography + ' Registration Crosstabs'] = pd.concat([target_dataframes_dict.get(geography + ' Registration Crosstabs'), horizontal_df], axis=0, sort=False)\n",
    "    \n",
    "    # Delete the total columns and rows\n",
    "    target_dataframes_dict[geography + ' Registration Crosstabs'] = target_dataframes_dict.get(geography + ' Registration Crosstabs')[target_dataframes_dict.get(geography + ' Registration Crosstabs').index != 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose ballots cast crosstabs for target districts\n",
    "print(\"Building target district ballots cast crosstabs at %s \" % (datetime.strftime(datetime.now(), '%H:%M:%S')))\n",
    "\n",
    "for geography in target_geographies_dict.keys():\n",
    "    target_dataframes_dict[geography + ' Ballots Cast Crosstabs'] = pd.DataFrame()\n",
    "    \n",
    "    for vertical in crosstab_criteria_list:\n",
    "        horizontal_df = pd.DataFrame()\n",
    "        for horizontal in crosstab_criteria_list:\n",
    "            try:\n",
    "                horizontal_df = pd.concat([horizontal_df, pd.crosstab(target_dataframes_dict.get(geography + ' Ballots Cast')[vertical], target_dataframes_dict.get(geography + ' Ballots Cast')[horizontal], margins=True)], axis=1, sort=True)\n",
    "                del horizontal_df['All']\n",
    "            except:\n",
    "                print(geography + horizontal)\n",
    "        target_dataframes_dict[geography + ' Ballots Cast Crosstabs'] = pd.concat([target_dataframes_dict.get(geography + ' Ballots Cast Crosstabs'), horizontal_df], axis=0, sort=False)\n",
    "    \n",
    "    # Add the precinct crosstabs only to the vertical crosstab axis\n",
    "    horizontal_df = pd.DataFrame()\n",
    "    for horizontal in crosstab_criteria_list:\n",
    "        try:\n",
    "            horizontal_df = pd.concat([horizontal_df, pd.crosstab(target_dataframes_dict.get(geography + ' Ballots Cast')['PRECINCT'], target_dataframes_dict.get(geography + ' Ballots Cast')[horizontal], margins=True)], axis=1, sort=True)\n",
    "            del horizontal_df['All']\n",
    "        except:\n",
    "            print(geography + horizontal)\n",
    "    target_dataframes_dict[geography + ' Ballots Cast Crosstabs'] = pd.concat([target_dataframes_dict.get(geography + ' Ballots Cast Crosstabs'), horizontal_df], axis=0, sort=False)\n",
    "    \n",
    "    # Delete the total columns and rows\n",
    "    target_dataframes_dict[geography + ' Ballots Cast Crosstabs'] = target_dataframes_dict.get(geography + ' Ballots Cast Crosstabs')[target_dataframes_dict.get(geography + ' Ballots Cast Crosstabs').index != 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save target district crosstabs to Excel\n",
    "writer = pd.ExcelWriter(target_crosstabs_file, engine='xlsxwriter')\n",
    "for geography in target_geographies_dict.keys():\n",
    "    target_dataframes_dict.get(geography + ' Registration Crosstabs').to_excel(writer, geography + ' Registration')\n",
    "    target_dataframes_dict.get(geography + ' Ballots Cast Crosstabs').to_excel(writer, geography + ' Ballots Cast')\n",
    "writer.save()\n",
    "print(\"Excel Export Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose some maps of the Democat results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import results file to dataframe\n",
    "results_df = pd.read_excel(result_xls_file, '2', header=1)\n",
    "results_df = results_df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = dem_candidates_list.copy()\n",
    "columns_list.insert(0, result_county_str)\n",
    "columns_list.append(dem_result_tot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow to only the columns you're interested in\n",
    "results_df = results_df[columns_list]\n",
    "\n",
    "results_df.rename(columns={result_county_str:'COUNTY'}, inplace=True)\n",
    "results_df.rename(columns={dem_result_tot_str:'Total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for percentage performance\n",
    "map_list = []\n",
    "for candidate in dem_candidates_list:\n",
    "    map_list.append(''.join(candidate.split(' ')[-1]))\n",
    "    results_df[''.join(candidate.split(' ')[-1:]) + ' %'] = (results_df[candidate].astype('int64') / \n",
    "                                                             results_df['Total'].astype('int64'))\n",
    "\n",
    "# Format County names to match map\n",
    "results_df['COUNTY'] = results_df['COUNTY'].str.upper()\n",
    "\n",
    "# Fix any na values\n",
    "results_df = results_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be defined again for some reason I don't get\n",
    "im = Image.open(r'D:\\Users\\bengen343\\Documents\\Constellation Political\\Constellation Operations\\Graphics\\CPC Star in LIne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the results\n",
    "# Define custom colormap\n",
    "for candidate in map_list:\n",
    "    \n",
    "    # Define colors to use with the party at hand\n",
    "    rvb = make_colormap([c(dem_colors_dict[candidate + ' Low']), c(dem_colors_dict[candidate + ' High'])])\n",
    "    \n",
    "    # Initiate the plot for the map\n",
    "    f, ax = plt.subplots(figsize=(13,15), dpi=300)\n",
    "    \n",
    "    # Load the shapefile map of Colorado counties\n",
    "    colorado_map = gpd.GeoDataFrame.from_file(map_shp_file)\n",
    "    \n",
    "    # Merge the turnout data into the map\n",
    "    colorado_map = colorado_map.merge(results_df, on='COUNTY')\n",
    "    \n",
    "    colorado_map['coords'] = colorado_map['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    colorado_map['coords'] = [coords[0] for coords in colorado_map['coords']]\n",
    "    \n",
    "    # Plot results for candidate\n",
    "    colorado_map.plot(ax=ax, column=candidate + ' %', cmap=rvb, linewidth=0.5, edgecolor='0.5')\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(election_str + '-' + candidate + ' %', fontname='Lato', fontsize='24')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Format the labels\n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=row['COUNTY'], xy=row['coords'], horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "        \n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=(\"{0:.1f}%\".format(row[candidate + ' %'] * 100)), xy=row['coords'], \n",
    "                     textcoords='offset points', xytext=(0,-10), horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "    \n",
    "    #Add watermark and webpage\n",
    "    im = im.resize((2000,2000))\n",
    "    plt.figimage(im, 1000, 150, alpha=0.20, zorder=3)\n",
    "    plt.figtext(0.5, 0.739, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', fontsize='14', \n",
    "                color='#686C6D')\n",
    "    plt.figtext(0.5, 0.725, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "    \n",
    "    # Export to image file\n",
    "    plt.savefig(r'W:\\My Documents\\\\' + election_fname_str + '_' + candidate + '_result_map.png', \n",
    "                pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose some maps of the Republican results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import results file to dataframe\n",
    "results_df = pd.read_excel(result_xls_file, '10', header=1)\n",
    "results_df = results_df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = rep_candidates_list.copy()\n",
    "columns_list.insert(0, result_county_str)\n",
    "columns_list.append(rep_result_tot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow to only the columns you're interested in\n",
    "results_df = results_df[columns_list]\n",
    "\n",
    "results_df.rename(columns={result_county_str:'COUNTY'}, inplace=True)\n",
    "results_df.rename(columns={rep_result_tot_str:'Total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for percentage performance\n",
    "map_list = []\n",
    "for candidate in rep_candidates_list:\n",
    "    map_list.append(''.join(candidate.split(' ')[-1]))\n",
    "    results_df[''.join(candidate.split(' ')[-1:]) + ' %'] = (results_df[candidate].astype('int64') / \n",
    "                                                             results_df['Total'].astype('int64'))\n",
    "\n",
    "# Format County names to match map\n",
    "results_df['COUNTY'] = results_df['COUNTY'].str.upper()\n",
    "\n",
    "# Fix any na values\n",
    "results_df = results_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the results\n",
    "# Define custom colormap\n",
    "for candidate in map_list:\n",
    "    \n",
    "    # Define colors to use with the party at hand\n",
    "    rvb = make_colormap([c(rep_colors_dict[candidate + ' Low']), c(rep_colors_dict[candidate + ' High'])])\n",
    "    \n",
    "    # Initiate the plot for the map\n",
    "    f, ax = plt.subplots(figsize=(13,15), dpi=300)\n",
    "    \n",
    "    # Load the shapefile map of Colorado counties\n",
    "    colorado_map = gpd.GeoDataFrame.from_file(map_shp_file)\n",
    "    \n",
    "    # Merge the turnout data into the map\n",
    "    colorado_map = colorado_map.merge(results_df, on='COUNTY')\n",
    "    \n",
    "    colorado_map['coords'] = colorado_map['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    colorado_map['coords'] = [coords[0] for coords in colorado_map['coords']]\n",
    "    \n",
    "    # Plot results for candidate\n",
    "    colorado_map.plot(ax=ax, column=candidate + ' %', cmap=rvb, linewidth=0.5, edgecolor='0.5')\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(election_str + '-' + candidate + ' %', fontname='Lato', fontsize='24')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Format the labels\n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=row['COUNTY'], xy=row['coords'], horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "        \n",
    "    for idx, row in colorado_map.iterrows():\n",
    "        plt.annotate(s=(\"{0:.1f}%\".format(row[candidate + ' %'] * 100)), xy=row['coords'], \n",
    "                     textcoords='offset points', xytext=(0,-10), horizontalalignment='center', \n",
    "                     fontsize=12).set_path_effects([PathEffects.withStroke(linewidth=3, foreground='w')])\n",
    "    \n",
    "    #Add watermark and webpage\n",
    "    im = im.resize((2000,2000))\n",
    "    plt.figimage(im, 1000, 150, alpha=0.20, zorder=3)\n",
    "    plt.figtext(0.5, 0.739+0.09, 'www.ConstellationPolitical.com', ha='center', va='center', fontname='Lato', fontsize='14', \n",
    "                color='#686C6D')\n",
    "    plt.figtext(0.5, 0.725+0.09, graph_time_str, ha='center', va='center', fontname='Lato', fontsize='12',color='#686C6D')\n",
    "    \n",
    "    # Export to image file\n",
    "    plt.savefig(r'W:\\My Documents\\\\' + election_fname_str + '_' + candidate + '_result_map.png', \n",
    "                pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make thumbnails out of the larger images\n",
    "for item in glob.glob(ftp_local_directory):\n",
    "    if ((os.path.isfile(item)) & ('thumb' not in item)):\n",
    "        im = Image.open(item)\n",
    "        f, e = os.path.splitext(item)\n",
    "        imResize = im.resize((int(im.size[0]/6),int(im.size[1]/6)), Image.ANTIALIAS)\n",
    "        imResize.save(f + '_thumb.png', 'PNG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = FTP(ftp_address)\n",
    "ftp.login(ftp_user, ftp_pass)\n",
    "ftp.cwd(ftp_directory)\n",
    "\n",
    "for fname in glob.glob(ftp_local_directory):\n",
    "    with open(fname, 'rb') as f:  \n",
    "        ftp.storbinary('STOR %s' % os.path.basename(fname), f)\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
